{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka and Python - Examples\n",
    "4OH4  \n",
    "January 2021\n",
    "\n",
    "This notebook contains examples of interfacing with Kafka using the `kafka-python` package. The threaded wrapper classes defined below allow demonstration of multi-producer and consumer systems on a single host, and show how allocating consumers to groups and partitioning topics can be used to scale workloads horizontally.\n",
    "\n",
    "As the wrapper classes are threaded, it is not possible to 'Run all cells' in this notebook - instead, execute them one-by-one using `Shift-Enter`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and setup\n",
    "\n",
    "Install the Python package requirements:  \n",
    "`pip install -r requirements.txt`\n",
    "\n",
    "Bring up the Kafka and Zookeeper containers using Docker Compose:   \n",
    "`docker-compose up`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple publish-subscribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "\n",
    "kafka_host = 'localhost:9092'\n",
    "\n",
    "def connect_kafka_producer():\n",
    "    _producer = None\n",
    "    try:\n",
    "        _producer = KafkaProducer(bootstrap_servers=[kafka_host], api_version=(0, 10))\n",
    "    except Exception as ex:\n",
    "        print('Exception while connecting Kafka')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return _producer\n",
    "    \n",
    "\n",
    "def publish_message(producer_instance, topic_name, key, value):\n",
    "    try:\n",
    "        key_bytes = bytes(key, encoding='utf-8')\n",
    "        value_bytes = bytes(value, encoding='utf-8')\n",
    "        producer_instance.send(topic_name, key=key_bytes, value=value_bytes)\n",
    "        producer_instance.flush()\n",
    "        print('Message published successfully.')\n",
    "    except Exception as ex:\n",
    "        print('Exception in publishing message')\n",
    "        print(str(ex))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message published successfully.\n"
     ]
    }
   ],
   "source": [
    "producer = connect_kafka_producer()\n",
    "\n",
    "topic_name = 'my_topic'\n",
    "key = 'a'\n",
    "value = '123'\n",
    "\n",
    "publish_message(producer, topic_name, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message received:\n",
      "\t Topic: my_topic\n",
      "\t Partition: 0\n",
      "\t Offset: 0\n",
      "\t Timestamp: 1610924763057\n",
      "\t Key/value: a:123\n"
     ]
    }
   ],
   "source": [
    "consumer = KafkaConsumer(topic_name, \n",
    "                         auto_offset_reset='earliest',\n",
    "                         bootstrap_servers=[kafka_host], \n",
    "                         api_version=(0, 10), \n",
    "                         consumer_timeout_ms=1000)\n",
    "\n",
    "for msg in consumer:\n",
    "    print('Message received:')\n",
    "    print(f'\\t Topic: {msg.topic}')\n",
    "    print(f'\\t Partition: {msg.partition}')\n",
    "    print(f'\\t Offset: {msg.offset}')\n",
    "    print(f'\\t Timestamp: {msg.timestamp}')\n",
    "    print(f'\\t Key/value: {msg.key.decode()}:{msg.value.decode()}')\n",
    "    \n",
    "consumer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple consumers and producers\n",
    "\n",
    "The threaded wrapper classes send and receive messages, with extra logging so that you can see whats going on. We send a key-value pair consisting of a randomly generated string and an incremental integer message ID - in production use the value would typically be more complex, such as JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import threading\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "\n",
    "logging.getLogger(\"python-kafka\").addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Base:\n",
    "    # Base class to store meta data and set up logging\n",
    "    \n",
    "    def __init__(self, id, topic, verbose):\n",
    "        \n",
    "        if id is not None:\n",
    "            self._id = id\n",
    "        else:\n",
    "            self._id = str(uuid.uuid1())[:8]\n",
    "            \n",
    "        self.topic = topic\n",
    "        self._verbose = verbose\n",
    "        \n",
    "        self._logger = logging.getLogger(\"python-kafka\")\n",
    "        if self._verbose:\n",
    "            self._logger.setLevel(\"DEBUG\")\n",
    "        else:\n",
    "            self._logger.setLevel(\"INFO\")\n",
    "            \n",
    "\n",
    "class Producer(Base):\n",
    "    # Wrapper class around KafkaProducer with logging and random, asynchronous message sending\n",
    "    \n",
    "    max_run_time = 10  # seconds\n",
    "    time_delta = 1.01 # seconds, between sending messages\n",
    "    \n",
    "    message_count = 0\n",
    "    \n",
    "    def __init__(self, id=None, topic=\"main_topic\", send_prob=0.5, verbose=True):\n",
    "        super().__init__(id, topic, verbose)\n",
    "        \n",
    "        self.send_prob = send_prob  # probability to send per time_delta [0-1]\n",
    "        \n",
    "        try:\n",
    "            self._producer = KafkaProducer(bootstrap_servers=[kafka_host], \n",
    "                                           client_id=self._id, \n",
    "                                           api_version=(0, 10))\n",
    "            self._logger.info(f\"Producer {self._id}: created\")\n",
    "        except Exception as ex:\n",
    "            self._logger.error(\"Exception occured while connecting to Kafka\")\n",
    "            self._logger.error(str(ex))\n",
    "            \n",
    "        self._running = True\n",
    "        self._thread = threading.Thread(target=self._random_send).start()\n",
    "        \n",
    "    def _random_send(self):\n",
    "        # Send a bunch of messages at random over a period of time\n",
    "        run_time = time.time()\n",
    "        time.sleep(self.time_delta)\n",
    "        while self._running and ((time.time()-run_time) < self.max_run_time):\n",
    "            if random.uniform(0,1) > (1-self.send_prob):\n",
    "                self.publish_message(topic_name=self.topic,\n",
    "                                    key=str(uuid.uuid1())[:8],\n",
    "                                    value=str(self.message_count))\n",
    "                self.message_count += 1\n",
    "            if not self._verbose:\n",
    "                print(\".\", end=\"\")\n",
    "                \n",
    "            time.sleep(self.time_delta)\n",
    "            \n",
    "        # block until all async messages are sent\n",
    "        self._producer.flush()\n",
    "        time.sleep(1)\n",
    "        self._logger.info(f\"Producer {self._id}: finished - {self.message_count} messages sent\\r\")\n",
    "        \n",
    "    def stop(self):\n",
    "        self._running = False\n",
    "    \n",
    "    def publish_message(self, topic_name, key, value):\n",
    "        try:\n",
    "            if key is not None:\n",
    "                key = bytes(key, encoding='utf-8')\n",
    "            if value is not None:\n",
    "                value = bytes(value, encoding='utf-8')\n",
    "            self._producer \\\n",
    "                .send(topic_name, key=key, value=value) \\\n",
    "                .add_callback(self.on_send_success) \\\n",
    "                .add_errback(self.on_send_error)\n",
    "            self._logger.debug(f\"Producer {self._id}: message queued for send\\r\")\n",
    "            \n",
    "            # block until all async messages are sent\n",
    "            # self._producer.flush()\n",
    "            \n",
    "        except Exception as ex:\n",
    "            self._logger.error(f\"Producer {self._id}: exception occured whilst publishing message\\r\")\n",
    "            print(str(ex))        \n",
    "    \n",
    "    def on_send_success(self, record_metadata):\n",
    "        # Callback function, called when message is sent\n",
    "        self._logger.debug(f\"Producer {self._id}: message sent successfully - topic: {record_metadata.topic}, partition: {record_metadata.partition}, offset: {record_metadata.offset}   \\r\")\n",
    "\n",
    "    def on_send_error(self, excp):\n",
    "        # Callback function, if there are errors during sending\n",
    "        self._logger.error(f\"Producer {self._id}: exception occured while sending message\\r\", exc_info=excp)\n",
    "        # handle exception\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Consumer(Base):\n",
    "    # Wrapper class around KafkaConsumer with logging and threading\n",
    "    \n",
    "    max_run_time = 12  # seconds\n",
    "    time_delta = 1 # seconds, between message polling\n",
    "    \n",
    "    message_count = 0\n",
    "    \n",
    "    def __init__(self, id=None, topic=\"main_topic\", group_id=None, verbose=True):\n",
    "        super().__init__(id, topic, verbose)\n",
    "        \n",
    "        try:\n",
    "            self._consumer = KafkaConsumer(self.topic,\n",
    "                                           client_id=self._id,\n",
    "                                           #auto_offset_reset='earliest', # if set, the offset begins at zero (or lowest)\n",
    "                                           group_id=group_id,\n",
    "                                           bootstrap_servers=[kafka_host], \n",
    "                                           api_version=(0, 10))\n",
    "            self._logger.info(f\"Consumer {self._id}: created\\r\")\n",
    "        except Exception as ex:\n",
    "            self._logger.error(\"Exception occured while connecting to Kafka\\r\", exc_info=ex)\n",
    "            \n",
    "        self._running = True\n",
    "        self._thread = threading.Thread(target=self._receive).start()\n",
    "        \n",
    "    def _receive(self):\n",
    "        # Receive messages from Kafka over a time period\n",
    "        run_time = time.time()\n",
    "        while self._running and ((time.time()-run_time) < self.max_run_time):\n",
    "            self._logger.debug(f\"Consumer {self._id}: polling for new messages\\r\")\n",
    "            response = self._consumer.poll(timeout_ms=self.time_delta*1000)\n",
    "            for topic_partition, messages in response.items():\n",
    "                for msg in messages:\n",
    "                    self._handle_message(msg)\n",
    "                    self.message_count += 1\n",
    "        self.stop()\n",
    "        \n",
    "    def stop(self):\n",
    "        self._running = False\n",
    "        self._consumer.close()\n",
    "        self._logger.info(f\"Consumer {self._id}: finished - {self.message_count} messages received\\r\")        \n",
    "        \n",
    "    def _handle_message(self, msg):\n",
    "        self._logger.debug(f\"Consumer {self._id}: message received - topic: {msg.topic}, partition: {msg.partition}, offset: {msg.offset}, key/value: {msg.key.decode()}:{msg.value.decode()}\\r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Consumer 96866eb8: created\n",
      "Consumer 96866eb8: polling for new messages\n",
      "Producer 96886f93: created\n",
      "Consumer 96866eb8: polling for new messages\n",
      "Producer 96886f93: message queued for send\n",
      "Consumer 96866eb8: message received - topic: main_topic, partition: 0, offset: 0, key/value: 97243cc9:0\n",
      "Producer 96886f93: message sent successfully - topic: main_topic, partition: 0, offset: 0   \n",
      "Consumer 96866eb8: polling for new messages\n",
      "Producer 96886f93: message queued for send\n",
      "Consumer 96866eb8: polling for new messages\n",
      "Producer 96886f93: message sent successfully - topic: main_topic, partition: 0, offset: 1   \n",
      "Consumer 96866eb8: message received - topic: main_topic, partition: 0, offset: 1, key/value: 97c13a56:1\n",
      "Consumer 96866eb8: polling for new messages\n",
      "Consumer 96866eb8: polling for new messages\n",
      "Producer 96886f93: message queued for send\n",
      "Producer 96886f93: message sent successfully - topic: main_topic, partition: 0, offset: 2   \n",
      "Consumer 96866eb8: message received - topic: main_topic, partition: 0, offset: 2, key/value: 985c1069:2\n",
      "Consumer 96866eb8: polling for new messages\n",
      "Producer 96886f93: message queued for send\n",
      "Consumer 96866eb8: polling for new messages\n",
      "Producer 96886f93: message sent successfully - topic: main_topic, partition: 0, offset: 3   \n",
      "Consumer 96866eb8: message received - topic: main_topic, partition: 0, offset: 3, key/value: 98f6a31b:3\n",
      "Consumer 96866eb8: polling for new messages\n",
      "Consumer 96866eb8: polling for new messages\n",
      "Consumer 96866eb8: polling for new messages\n",
      "Producer 96886f93: message queued for send\n",
      "Consumer 96866eb8: message received - topic: main_topic, partition: 0, offset: 4, key/value: 9a2b505e:4\n",
      "Producer 96886f93: message sent successfully - topic: main_topic, partition: 0, offset: 4   \n",
      "Consumer 96866eb8: polling for new messages\n",
      "Consumer 96866eb8: polling for new messages\n",
      "Producer 96886f93: message queued for send\n",
      "Producer 96886f93: message sent successfully - topic: main_topic, partition: 0, offset: 5   \n",
      "Consumer 96866eb8: message received - topic: main_topic, partition: 0, offset: 5, key/value: 9ac646a0:5\n",
      "Consumer 96866eb8: polling for new messages\n",
      "Consumer 96866eb8: polling for new messages\n",
      "Producer 96886f93: message queued for send\n",
      "Consumer 96866eb8: message received - topic: main_topic, partition: 0, offset: 6, key/value: 9b610000:6\n",
      "Producer 96886f93: message sent successfully - topic: main_topic, partition: 0, offset: 6   \n",
      "Consumer 96866eb8: polling for new messages\n",
      "Consumer 96866eb8: polling for new messages\n",
      "Consumer 96866eb8: polling for new messages\n",
      "Consumer 96866eb8: polling for new messages\n",
      "Producer 96886f93: finished - 7 messages sent\n",
      "Consumer 96866eb8: finished - 7 messages received\n"
     ]
    }
   ],
   "source": [
    "# One consumer, one producer\n",
    "c1 = Consumer()\n",
    "p1 = Producer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Consumer a0d1d06e: created\n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Producer a0d37e30: created\n",
      "Producer a0d52bdb: created\n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Producer a0d37e30: message queued for send\n",
      "Consumer a0d1d06e: message received - topic: main_topic, partition: 0, offset: 7, key/value: a16f6a35:0\n",
      "Producer a0d37e30: message sent successfully - topic: main_topic, partition: 0, offset: 7   \n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Producer a0d37e30: message queued for send\n",
      "Consumer a0d1d06e: message received - topic: main_topic, partition: 0, offset: 8, key/value: a20ab167:1\n",
      "Producer a0d52bdb: message queued for send\n",
      "Producer a0d37e30: message sent successfully - topic: main_topic, partition: 0, offset: 8   \n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Producer a0d52bdb: message sent successfully - topic: main_topic, partition: 0, offset: 9   \n",
      "Consumer a0d1d06e: message received - topic: main_topic, partition: 0, offset: 9, key/value: a20b268c:0\n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Producer a0d37e30: message queued for send\n",
      "Consumer a0d1d06e: message received - topic: main_topic, partition: 0, offset: 10, key/value: a33fc996:2\n",
      "Producer a0d37e30: message sent successfully - topic: main_topic, partition: 0, offset: 10   \n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Producer a0d37e30: message queued for send\n",
      "Producer a0d37e30: message sent successfully - topic: main_topic, partition: 0, offset: 11   \n",
      "Consumer a0d1d06e: message received - topic: main_topic, partition: 0, offset: 11, key/value: a3da36ed:3\n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Producer a0d52bdb: message queued for send\n",
      "Consumer a0d1d06e: message received - topic: main_topic, partition: 0, offset: 12, key/value: a3dca49d:1\n",
      "Producer a0d52bdb: message sent successfully - topic: main_topic, partition: 0, offset: 12   \n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Producer a0d37e30: message queued for send\n",
      "Consumer a0d1d06e: message received - topic: main_topic, partition: 0, offset: 13, key/value: a50efe57:4\n",
      "Producer a0d37e30: message sent successfully - topic: main_topic, partition: 0, offset: 13   \n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Producer a0d52bdb: message queued for send\n",
      "Consumer a0d1d06e: message received - topic: main_topic, partition: 0, offset: 14, key/value: a511a483:2\n",
      "Producer a0d52bdb: message sent successfully - topic: main_topic, partition: 0, offset: 14   \n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Producer a0d52bdb: message queued for send\n",
      "Consumer a0d1d06e: message received - topic: main_topic, partition: 0, offset: 15, key/value: a5ac4fb7:3\n",
      "Producer a0d52bdb: message sent successfully - topic: main_topic, partition: 0, offset: 15   \n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Producer a0d52bdb: message queued for send\n",
      "Producer a0d52bdb: message sent successfully - topic: main_topic, partition: 0, offset: 16   \n",
      "Consumer a0d1d06e: message received - topic: main_topic, partition: 0, offset: 16, key/value: a647321e:4\n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Producer a0d37e30: finished - 5 messages sent\n",
      "Producer a0d52bdb: finished - 5 messages sent\n",
      "Consumer a0d1d06e: polling for new messages\n",
      "Consumer a0d1d06e: finished - 10 messages received\n"
     ]
    }
   ],
   "source": [
    "# One consumer, two producers\n",
    "c1 = Consumer()\n",
    "p1 = Producer()\n",
    "p2 = Producer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again - we see here that the single consumer picks up all messages from both producers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Consumer 1: created\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: created\n",
      "Consumer 2: polling for new messages\n",
      "Producer e573e501: created\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Producer e573e501: message queued for send\n",
      "Consumer 2: message received - topic: main_topic, partition: 0, offset: 29, key/value: e60f134e:0\n",
      "Consumer 1: message received - topic: main_topic, partition: 0, offset: 29, key/value: e60f134e:0\n",
      "Producer e573e501: message sent successfully - topic: main_topic, partition: 0, offset: 29   \n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Producer e573e501: message queued for send\n",
      "Producer e573e501: message sent successfully - topic: main_topic, partition: 0, offset: 30   \n",
      "Consumer 1: message received - topic: main_topic, partition: 0, offset: 30, key/value: e6a9f1d9:1\n",
      "Consumer 2: message received - topic: main_topic, partition: 0, offset: 30, key/value: e6a9f1d9:1\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Producer e573e501: message queued for send\n",
      "Producer e573e501: message sent successfully - topic: main_topic, partition: 0, offset: 31   \n",
      "Consumer 1: message received - topic: main_topic, partition: 0, offset: 31, key/value: e74484c7:2\n",
      "Consumer 2: message received - topic: main_topic, partition: 0, offset: 31, key/value: e74484c7:2\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Producer e573e501: message queued for send\n",
      "Producer e573e501: message sent successfully - topic: main_topic, partition: 0, offset: 32   \n",
      "Consumer 1: message received - topic: main_topic, partition: 0, offset: 32, key/value: e7e007d7:3\n",
      "Consumer 2: message received - topic: main_topic, partition: 0, offset: 32, key/value: e7e007d7:3\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Producer e573e501: message queued for send\n",
      "Consumer 2: message received - topic: main_topic, partition: 0, offset: 33, key/value: e87b98d3:4\n",
      "Consumer 1: message received - topic: main_topic, partition: 0, offset: 33, key/value: e87b98d3:4\n",
      "Producer e573e501: message sent successfully - topic: main_topic, partition: 0, offset: 33   \n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Producer e573e501: message queued for send\n",
      "Producer e573e501: message sent successfully - topic: main_topic, partition: 0, offset: 34   \n",
      "Consumer 1: message received - topic: main_topic, partition: 0, offset: 34, key/value: e9167920:5\n",
      "Consumer 2: message received - topic: main_topic, partition: 0, offset: 34, key/value: e9167920:5\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Producer e573e501: message queued for send\n",
      "Producer e573e501: message sent successfully - topic: main_topic, partition: 0, offset: 35   \n",
      "Consumer 1: message received - topic: main_topic, partition: 0, offset: 35, key/value: ea4b9fd1:6\n",
      "Consumer 2: message received - topic: main_topic, partition: 0, offset: 35, key/value: ea4b9fd1:6\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Producer e573e501: message queued for send\n",
      "Producer e573e501: message sent successfully - topic: main_topic, partition: 0, offset: 36   \n",
      "Consumer 2: message received - topic: main_topic, partition: 0, offset: 36, key/value: eae635c4:7\n",
      "Consumer 1: message received - topic: main_topic, partition: 0, offset: 36, key/value: eae635c4:7\n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Producer e573e501: finished - 8 messages sent\n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: finished - 8 messages received\n",
      "Consumer 1: finished - 8 messages received\n"
     ]
    }
   ],
   "source": [
    "# Two consumers, one producer \n",
    "c1 = Consumer(id=1)\n",
    "c2 = Consumer(id=2)\n",
    "p1 = Producer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running two consumers, they both pick up all the messages. Whilst this could sometimes be useful, in most cases this is undesireable as it means that effort is being duplicated. To effectively scale our application workload across multiple nodes, we want them to coordinate to split up the work between them.\n",
    "\n",
    "To make this happen, we assign the consumers to the same consumer group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Consumer 1: created\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: created\n",
      "Consumer 2: polling for new messages\n",
      "Producer 059c8141: created\n",
      "Producer 059c8141: message queued for send\n",
      "Producer 059c8141: message sent successfully - topic: main_topic, partition: 0, offset: 44   \n",
      "Producer 059c8141: message queued for send\n",
      "Producer 059c8141: message sent successfully - topic: main_topic, partition: 0, offset: 45   \n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: message received - topic: main_topic, partition: 0, offset: 44, key/value: 0637e2ad:0\n",
      "Consumer 1: message received - topic: main_topic, partition: 0, offset: 45, key/value: 06d30007:1\n",
      "Consumer 1: polling for new messages\n",
      "Producer 059c8141: message queued for send\n",
      "Producer 059c8141: message sent successfully - topic: main_topic, partition: 0, offset: 46   \n",
      "Consumer 1: message received - topic: main_topic, partition: 0, offset: 46, key/value: 0807a000:2\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Producer 059c8141: message queued for send\n",
      "Producer 059c8141: message sent successfully - topic: main_topic, partition: 0, offset: 47   \n",
      "Consumer 1: message received - topic: main_topic, partition: 0, offset: 47, key/value: 08a20a3e:3\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Producer 059c8141: message queued for send\n",
      "Consumer 1: message received - topic: main_topic, partition: 0, offset: 48, key/value: 09d707d7:4\n",
      "Producer 059c8141: message sent successfully - topic: main_topic, partition: 0, offset: 48   \n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Producer 059c8141: message queued for send\n",
      "Producer 059c8141: message sent successfully - topic: main_topic, partition: 0, offset: 49   \n",
      "Consumer 1: message received - topic: main_topic, partition: 0, offset: 49, key/value: 0a718a86:5\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Producer 059c8141: message queued for send\n",
      "Producer 059c8141: message sent successfully - topic: main_topic, partition: 0, offset: 50   \n",
      "Consumer 1: message received - topic: main_topic, partition: 0, offset: 50, key/value: 0b0c1b7a:6\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: polling for new messages\n",
      "Producer 059c8141: finished - 7 messages sent\n",
      "Consumer 2: polling for new messages\n",
      "Consumer 1: finished - 7 messages received\n",
      "Consumer 2: finished - 0 messages received\n"
     ]
    }
   ],
   "source": [
    "# Two consumers, one producer \n",
    "c1 = Consumer(id=1, group_id='consumers1')\n",
    "c2 = Consumer(id=2, group_id='consumers1')\n",
    "p1 = Producer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the consumers are no longer duplicating their effort, there is a complication here - now all the messages are being processed by a single consumer. This is because our topic only has a single *partition*.\n",
    "\n",
    "Kafka dividies a topic into partitions, and only one consumer from a consumer group can consume from each partition. As a general rule, the number of partitions in a topic should be greater than the number of consumers.\n",
    "\n",
    "Further reading:\n",
    "https://blog.cloudera.com/scalability-of-kafka-messaging-using-consumer-groups/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 partition(s) found, identifiers: {0}\n"
     ]
    }
   ],
   "source": [
    "# Print the partition IDs\n",
    "topic = \"main_topic\"\n",
    "consumer = KafkaConsumer(\n",
    "    topic, bootstrap_servers=kafka_host)\n",
    "\n",
    "partition_ids = consumer.partitions_for_topic(topic)\n",
    "consumer.close()\n",
    "\n",
    "print(f\"{len(partition_ids)} partition(s) found, identifiers: {partition_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new topic with multiple partitions\n",
    "\n",
    "We can use the admin client interface to create a new topic, and set the number of partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreateTopicsResponse_v3(throttle_time_ms=0, topic_errors=[(topic='new_topic', error_code=0, error_message=None)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kafka.admin import KafkaAdminClient, NewTopic\n",
    "\n",
    "admin_client = KafkaAdminClient(bootstrap_servers=kafka_host)\n",
    "\n",
    "topic_list = []\n",
    "topic_list.append(NewTopic(name=\"new_topic\", num_partitions=9, replication_factor=1))\n",
    "admin_client.create_topics(new_topics=topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Consumer 1: created\n",
      "Consumer 2: created\n",
      "Consumer 3: created\n",
      "Producer 1881cfcb: created\n",
      "Producer 1883083b: created\n",
      "Producer 1883cf35: created\n",
      "Producer 18852b3b: created\n",
      "Producer 18863d1f: created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Producer 1881cfcb: finished - 89 messages sent\n",
      "Producer 1883083b: finished - 89 messages sent\n",
      "Producer 1883cf35: finished - 89 messages sent\n",
      "Producer 18852b3b: finished - 89 messages sent\n",
      "Producer 18863d1f: finished - 89 messages sent\n",
      "Consumer 3: finished - 54 messages received\n",
      "Consumer 1: finished - 75 messages received\n",
      "Consumer 2: finished - 54 messages received\n"
     ]
    }
   ],
   "source": [
    "# Two consumers, one producer\n",
    "c1 = Consumer(id=\"1\", topic=\"new_topic\", group_id='consumers2', verbose=False)\n",
    "c2 = Consumer(id=\"2\", topic=\"new_topic\", group_id='consumers2', verbose=False)\n",
    "c3 = Consumer(id=\"3\", topic=\"new_topic\", group_id='consumers2', verbose=False)\n",
    "producer_array = []\n",
    "for _ in range(5):\n",
    "    this_producer = Producer(topic=\"new_topic\", send_prob=1, verbose=False)\n",
    "    this_producer.time_delta = 0.1  # secs, for high-rate sending\n",
    "    producer_array.append(this_producer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with the consumers in a new group and the number of partitions higher, the messages are divided (at random) between the three consumers.\n",
    "\n",
    "Note: in the producer, we generate a random string as the `key` for each message. This is hashed by the message broker to assign messages to partitions - if every message had the same key, they would all be asigned to the same partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Administration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete 'new_topic'\n",
    "admin_client.delete_topics(topics=['new_topic'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
